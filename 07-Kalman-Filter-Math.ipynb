{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Table of Contents](./table_of_contents.ipynb)\n",
    "\n",
    "# Kalman Filter Math\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "#format the book\n",
    "import book_format\n",
    "book_format.set_style()\n",
    "\n",
    "If you've gotten this far I hope that you are thinking that the Kalman filter's fearsome reputation is somewhat undeserved. Sure, I hand waved some equations away, but I hope implementation has been fairly straightforward for you. The underlying concept is quite straightforward - take two measurements, or a measurement and a prediction, and choose the output to be somewhere between the two. If you believe the measurement more your guess will be closer to the measurement, and if you believe the prediction is more accurate your guess will lie closer to it. That's not rocket science (little joke - it is exactly this math that got Apollo to the moon and back!). \n",
    "\n",
    "To be honest I have been choosing my problems carefully. For an arbitrary problem designing the Kalman filter matrices can be extremely difficult. I haven't been *too tricky*, though. Equations like Newton's equations of motion can be trivially computed for Kalman filter applications, and they make up the bulk of the kind of problems that we want to solve. \n",
    "\n",
    "I have illustrated the concepts with code and reasoning, not math. But there are topics that do require more mathematics than I have used so far. This chapter presents the math that you will need for the rest of the book.\n",
    "\n",
    "## Modeling a Dynamic System\n",
    "\n",
    "A *dynamic system* is a physical system whose state (position, temperature, etc) evolves over time. Calculus is the math of changing values, so we use differential equations to model dynamic systems. Some systems cannot be modeled with differential equations, but we will not encounter those in this book.\n",
    "\n",
    "Modeling dynamic systems is properly the topic of several college courses. To an extent there is no substitute for a few semesters of ordinary and partial differential equations followed by a graduate course in control system theory. If you are a hobbyist, or trying to solve one very specific filtering problem at work you probably do not have the time and/or inclination to devote a year or more to that education.\n",
    "\n",
    "Fortunately, I can present enough of the theory to allow us to create the system equations for many different Kalman filters. My goal is to get you to the stage where you can read a publication and understand it well enough to implement the algorithms. The background math is deep, but in practice we end up using a few simple techniques. \n",
    "\n",
    "This is the longest section of pure math in this book. You will need to master everything in this section to understand the Extended Kalman filter (EKF), the most common nonlinear filter. I do cover more modern filters that do not require as much of this math. You can choose to skim now, and come back to this if you decide to learn the EKF.\n",
    "\n",
    "We need to start by understanding the underlying equations and assumptions that the Kalman filter uses. We are trying to model real world phenomena, so what do we have to consider?\n",
    "\n",
    "Each physical system has a process. For example, a car traveling at a certain velocity goes so far in a fixed amount of time, and its velocity varies as a function of its acceleration. We describe that behavior with the well known Newtonian equations that we learned in high school.\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "v&=at\\\\\n",
    "x &= \\frac{1}{2}at^2 + v_0t + x_0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Once we learned calculus we saw them in this form:\n",
    "\n",
    "$$ \\mathbf v = \\frac{d \\mathbf x}{d t}, \n",
    "\\quad \\mathbf a = \\frac{d \\mathbf v}{d t} = \\frac{d^2 \\mathbf x}{d t^2}\n",
    "$$\n",
    "\n",
    "A typical automobile tracking problem would have you compute the distance traveled given a constant velocity or acceleration, as we did in previous chapters. But, of course we know this is not all that is happening. No car travels on a perfect road. There are bumps, wind drag, and hills that raise and lower the speed. The suspension is a mechanical system with friction and imperfect springs.\n",
    "\n",
    "Perfectly modeling a system is impossible except for the most trivial problems. We are forced to make a simplification. At any time $t$ we say that the true state (such as the position of our car) is the predicted value from the imperfect model plus some unknown *process noise*:\n",
    "\n",
    "$$\n",
    "x(t) = x_{pred}(t) + noise(t)\n",
    "$$\n",
    "\n",
    "This is not meant to imply that $noise(t)$ is a function that we can derive analytically. It is merely a statement of fact - we can always describe the true value as the predicted value  plus the process noise. \"Noise\" does not imply random events. If we are tracking a thrown ball in the atmosphere, and our model assumes the ball is in a vacuum, then the effect of air drag is process noise in this context.\n",
    "\n",
    "In the next section we will learn techniques to convert a set of higher order differential equations into a set of first-order differential equations.  After the conversion the model of the system without noise is:\n",
    "\n",
    "$$ \\dot{\\mathbf x} = \\mathbf{Ax}$$\n",
    "\n",
    "$\\mathbf A$ is known as the *systems dynamics matrix* as it describes the dynamics of the system. Now we need to model the noise. We will call that $\\mathbf w$, and add it to the equation. \n",
    "\n",
    "$$ \\dot{\\mathbf x} = \\mathbf{Ax} + \\mathbf w$$\n",
    "\n",
    "$\\mathbf w$ may strike you as a poor choice for the name, but you will soon see that the Kalman filter assumes *white* noise.\n",
    "\n",
    "Finally, we need to consider any inputs into the system. We assume an input $\\mathbf u$, and that there exists a linear model that defines how that input changes the system. For example, pressing the accelerator in your car makes it accelerate, and gravity causes balls to fall. Both are control inputs. We will need a matrix $\\mathbf B$ to convert $u$ into the effect on the system. We add that into our equation:\n",
    "\n",
    "$$ \\dot{\\mathbf x} = \\mathbf{Ax} + \\mathbf{Bu} + \\mathbf{w}$$\n",
    "\n",
    "And that's it. That is one of the equations that Dr. Kalman set out to solve, and he found an optimal estimator if we assume certain properties of $\\mathbf w$.\n",
    "\n",
    "## State-Space Representation of Dynamic Systems\n",
    "\n",
    "We've derived the equation\n",
    "\n",
    "$$ \\dot{\\mathbf x} = \\mathbf{Ax}+ \\mathbf{Bu} + \\mathbf{w}$$\n",
    "\n",
    "However, we are not interested in the derivative of $\\mathbf x$, but in $\\mathbf x$ itself. Ignoring the noise for a moment, we want an equation that recursively finds the value of $\\mathbf x$ at time $t_k$ in terms of $\\mathbf x$ at time $t_{k-1}$:\n",
    "\n",
    "$$\\mathbf x(t_k) = \\mathbf F(\\Delta t)\\mathbf x(t_{k-1}) + \\mathbf B(t_k)\\mathbf u (t_k)$$\n",
    "\n",
    "Convention allows us to write $\\mathbf x(t_k)$ as $\\mathbf x_k$, which means the \n",
    "the value of $\\mathbf x$ at the $k^{th}$ value of $t$.\n",
    "\n",
    "$$\\mathbf x_k = \\mathbf{Fx}_{k-1} + \\mathbf B_k\\mathbf u_k$$\n",
    "\n",
    "$\\mathbf F$ is the familiar *state transition matrix*, named due to its ability to transition the state's value between discrete time steps. It is very similar to the system dynamics matrix $\\mathbf A$. The difference is that $\\mathbf A$ models a set of linear differential equations, and is continuous. $\\mathbf F$ is discrete, and represents a set of linear equations (not differential equations) which transitions $\\mathbf x_{k-1}$ to $\\mathbf x_k$ over a discrete time step $\\Delta t$. \n",
    "\n",
    "Finding this matrix is often quite difficult. The equation $\\dot x = v$ is the simplest possible differential equation and we trivially integrate it as:\n",
    "\n",
    "$$ \\int\\limits_{x_{k-1}}^{x_k}  \\mathrm{d}x = \\int\\limits_{0}^{\\Delta t} v\\, \\mathrm{d}t $$\n",
    "$$x_k-x_{k-1} = v \\Delta t$$\n",
    "$$x_k = v \\Delta t + x_{k-1}$$\n",
    "\n",
    "This equation is *recursive*: we compute the value of $x$ at time $k$ based on its value at time $k-1$. This recursive form enables us to represent the system (process model) in the form required by the Kalman filter:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathbf x_k &= \\mathbf{Fx}_{k-1}  \\\\\n",
    "&= \\begin{bmatrix} 1 & \\Delta t \\\\ 0 & 1\\end{bmatrix}\n",
    "\\begin{bmatrix}x_{k-1} \\\\ \\dot x_{k-1}\\end{bmatrix}\n",
    "\\end{aligned}$$\n",
    "\n",
    "We can do that only because $\\dot x = v$ is simplest differential equation possible. Almost all other in physical systems result in more complicated differential equation which do not yield to this approach. \n",
    "\n",
    "*State-space* methods became popular around the time of the Apollo missions, largely due to the work of Dr. Kalman. The idea is simple. Model a system with a set of  $n^{th}$-order differential equations. Convert them into an equivalent set of first-order differential equations. Put them into the vector-matrix form used in the previous section: $\\dot{\\mathbf x} = \\mathbf{Ax} + \\mathbf{Bu}$. Once in this form we use of several techniques to convert these linear differential equations into the recursive equation:\n",
    "\n",
    "$$ \\mathbf x_k = \\mathbf{Fx}_{k-1} + \\mathbf B_k\\mathbf u_k$$\n",
    "\n",
    "Some books call the state transition matrix the *fundamental matrix*. Many use $\\mathbf \\Phi$ instead of $\\mathbf F$. Sources based heavily on control theory tend to use these forms.\n",
    "\n",
    "These are called *state-space* methods because we are expressing the solution of the differential equations in terms of the system state. \n",
    "\n",
    "### Forming First Order Equations from Higher Order Equations\n",
    "\n",
    "Many models of physical systems require second or higher order differential equations with control input $u$:\n",
    "\n",
    "$$a_n \\frac{d^ny}{dt^n} + a_{n-1} \\frac{d^{n-1}y}{dt^{n-1}} +  \\dots + a_2 \\frac{d^2y}{dt^2} + a_1 \\frac{dy}{dt} + a_0 = u$$\n",
    "\n",
    "State-space methods require first-order equations. Any higher order system of equations can be reduced to first-order by defining extra variables for the derivatives and then solving. \n",
    "\n",
    "\n",
    "Let's do an example. Given the system $\\ddot{x} - 6\\dot x + 9x = u$ find the equivalent first order equations. I've used the dot notation for the time derivatives for clarity.\n",
    "\n",
    "The first step is to isolate the highest order term onto one side of the equation.\n",
    "\n",
    "$$\\ddot{x} = 6\\dot x - 9x + u$$\n",
    "\n",
    "We define two new variables:\n",
    "\n",
    "$$\\begin{aligned} x_1(t) &= x \\\\\n",
    "x_2(t) &= \\dot x\n",
    "\\end{aligned}$$\n",
    "\n",
    "Now we will substitute these into the original equation and solve. The solution yields a set of first-order equations in terms of these new variables. It is conventional to drop the $(t)$ for notational convenience.\n",
    "\n",
    "We know that $\\dot x_1 = x_2$ and that $\\dot x_2 = \\ddot{x}$. Therefore\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\dot x_2 &= \\ddot{x} \\\\\n",
    "         &= 6\\dot x - 9x + u\\\\\n",
    "         &= 6x_2-9x_1 + u\n",
    "\\end{aligned}$$\n",
    "\n",
    "Therefore our first-order system of equations is\n",
    "\n",
    "$$\\begin{aligned}\\dot x_1 &= x_2 \\\\\n",
    "\\dot x_2 &= 6x_2-9x_1 + u\\end{aligned}$$\n",
    "\n",
    "If you practice this a bit you will become adept at it. Isolate the highest term, define a new variable and its derivatives, and then substitute.\n",
    "\n",
    "### 🧠 如何将高阶微分方程转化为一阶微分方程组（状态空间形式）\n",
    "\n",
    "很多物理系统（如控制系统、电路系统）由二阶或更高阶的微分方程描述。但为了使用状态空间方法建模分析，我们需要将它们转换为一阶微分方程组。\n",
    "\n",
    "### 🎓 举例说明\n",
    "\n",
    "给定系统：\n",
    "\n",
    "$$\n",
    "\\ddot{x} - 6\\dot{x} + 9x = u\n",
    "$$\n",
    "\n",
    "### ✅ 第一步：将最高阶导数（$\\ddot{x}$）单独列在等式左边\n",
    "\n",
    "$$\n",
    "\\ddot{x} = 6\\dot{x} - 9x + u\n",
    "$$\n",
    "\n",
    "### ✅ 第二步：定义新变量\n",
    "\n",
    "将原始变量及其导数替换成新变量：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_1 &= x \\\\\n",
    "x_2 &= \\dot{x}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "因此：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dot{x}_1 &= x_2 \\\\\n",
    "\\dot{x}_2 &= \\ddot{x} = 6x_2 - 9x_1 + u\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### ✅ 得到的一阶系统（状态空间表示）\n",
    "\n",
    "最终得到如下的状态空间形式：\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\dot{x}_1 &= x_2 \\\\\n",
    "\\dot{x}_2 &= 6x_2 - 9x_1 + u\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "### 🔁 总结操作步骤\n",
    "\n",
    "1. **把最高阶导数移到等式左边**\n",
    "2. **引入新变量表示原始变量及其导数**\n",
    "3. **写出每个新变量的一阶导数表达式**\n",
    "4. **得到一组一阶微分方程**\n",
    "\n",
    "这种方法在控制理论、系统建模、数值求解等场景中非常常见和有用。\n",
    "\n",
    "\n",
    "### First Order Differential Equations In State-Space Form (把任何high order to first order linear matrix)\n",
    "\n",
    "Substituting the newly defined variables from the previous section:\n",
    "\n",
    "$$\\frac{dx_1}{dt} = x_2,\\,  \n",
    "\\frac{dx_2}{dt} = x_3, \\, ..., \\, \n",
    "\\frac{dx_{n-1}}{dt} = x_n$$\n",
    "\n",
    "into the first order equations yields: \n",
    "\n",
    "$$\\frac{dx_n}{dt} = \\frac{1}{a_n}\\sum\\limits_{i=0}^{n-1}a_ix_{i+1} + \\frac{1}{a_n}u\n",
    "$$\n",
    "\n",
    "\n",
    "Using vector-matrix notation we have:\n",
    "\n",
    "$$\\begin{bmatrix}\\frac{dx_1}{dt} \\\\ \\frac{dx_2}{dt} \\\\ \\vdots \\\\ \\frac{dx_n}{dt}\\end{bmatrix} = \n",
    "\\begin{bmatrix}\\dot x_1 \\\\ \\dot x_2 \\\\ \\vdots \\\\ \\dot x_n\\end{bmatrix}=\n",
    "\\begin{bmatrix}0 & 1 & 0 &\\cdots & 0 \\\\\n",
    "0 & 0 & 1 & \\cdots & 0 \\\\\n",
    "\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
    "-\\frac{a_0}{a_n} & -\\frac{a_1}{a_n} & -\\frac{a_2}{a_n} & \\cdots & -\\frac{a_{n-1}}{a_n}\\end{bmatrix}\n",
    "\\begin{bmatrix}x_1 \\\\ x_2 \\\\ \\vdots \\\\ x_n\\end{bmatrix} + \n",
    "\\begin{bmatrix}0 \\\\ 0 \\\\ \\vdots \\\\ \\frac{1}{a_n}\\end{bmatrix}u$$\n",
    "\n",
    "which we then write as $\\dot{\\mathbf x} = \\mathbf{Ax} + \\mathbf{B}u$.\n",
    "\n",
    "### Finding the Fundamental Matrix for Time Invariant Systems\n",
    "\n",
    "We express the system equations in state-space form with\n",
    "\n",
    "$$ \\dot{\\mathbf x} = \\mathbf{Ax}$$\n",
    "\n",
    "where $\\mathbf A$ is the system dynamics matrix, and want to find the *fundamental matrix* $\\mathbf F$ that propagates the state $\\mathbf x$ over the interval $\\Delta t$ with the equation\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathbf x(t_k) = \\mathbf F(\\Delta t)\\mathbf x(t_{k-1})\\end{aligned}$$\n",
    "\n",
    "In other words, $\\mathbf A$ is a set of continuous differential equations, and we need $\\mathbf F$ to be a set of discrete linear equations that computes the change in $\\mathbf A$ over a discrete time step.\n",
    "\n",
    "It is conventional to drop the $t_k$ and $(\\Delta t)$ and use the notation\n",
    "\n",
    "$$\\mathbf x_k = \\mathbf {Fx}_{k-1}$$\n",
    "\n",
    "Broadly speaking there are three common ways to find this matrix for Kalman filters. The technique most often used is the matrix exponential. Linear Time Invariant Theory, also known as LTI System Theory, is a second technique. Finally, there are numerical techniques. You may know of others, but these three are what you will most likely encounter in the Kalman filter literature and praxis.\n",
    "\n",
    "### 🧠 如何理解“Time Invariant System 的 Fundamental Matrix（基础矩阵）”\n",
    "\n",
    "我们从状态空间方程出发：\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf x} = \\mathbf{A}\\mathbf{x}\n",
    "$$\n",
    "\n",
    "其中 $\\mathbf{A}$ 是系统的动态矩阵（常数矩阵，表示系统的连续时间行为），我们的目标是找到一个 *fundamental matrix*（基础矩阵）$\\mathbf{F}$，它可以将状态在离散时间步之间传播，即：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t_k) = \\mathbf{F}(\\Delta t)\\mathbf{x}(t_{k-1})\n",
    "$$\n",
    "\n",
    "这意味着：虽然 $\\mathbf{A}$ 是一个描述连续变化的微分方程系统，我们需要将它“离散化”，得到一个能用来在有限时间步内传播状态的线性变换 $\\mathbf{F}$。\n",
    "\n",
    "为了简化记号，我们通常省略时间变量，写成更简洁的形式：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}_k = \\mathbf{F}\\mathbf{x}_{k-1}\n",
    "$$\n",
    "\n",
    "### ✅ 为什么需要 $\\mathbf{F}$？\n",
    "\n",
    "因为在许多实际应用（比如 Kalman Filter）中，我们是在 **离散的时间步长 $\\Delta t$** 下对系统建模的。但系统的真实动力学是连续的，因此需要从 $\\mathbf{A}$ 推导出一个离散的变换 $\\mathbf{F}$。\n",
    "\n",
    "### ✅ 如何求 $\\mathbf{F}$？\n",
    "\n",
    "在卡尔曼滤波（Kalman Filter）相关文献中，常见的三种方法有：\n",
    "\n",
    "1. **矩阵指数法（Matrix Exponential）**：最常用的方法  \n",
    "   $$\n",
    "   \\mathbf{F} = e^{\\mathbf{A} \\Delta t}\n",
    "   $$\n",
    "   通常通过泰勒展开或数值方法计算。\n",
    "\n",
    "2. **线性时不变系统理论（LTI System Theory）**：适用于已知 $\\mathbf{A}$ 特征结构的系统，基于解析解进行推导。\n",
    "\n",
    "3. **数值方法（Numerical Techniques）**：如数值积分、欧拉法、RK方法，适用于复杂或非线性系统的近似计算。\n",
    "\n",
    "### 📌 小结\n",
    "\n",
    "- $\\dot{\\mathbf{x}} = \\mathbf{A}\\mathbf{x}$ 是连续系统的描述  \n",
    "- $\\mathbf{x}_k = \\mathbf{F}\\mathbf{x}_{k-1}$ 是离散系统的描述  \n",
    "- 关键任务是：**从 $\\mathbf{A}$ 推导出 $\\mathbf{F}$，用于离散时间分析**\n",
    "\n",
    "这些技巧在卡尔曼滤波器、机器人、控制系统建模中都非常重要。\n",
    "\n",
    "### The Matrix Exponential\n",
    "\n",
    "The solution to the equation $\\frac{dx}{dt} = kx$ can be found by:\n",
    "\n",
    "$$\\begin{gathered}\\frac{dx}{dt} = kx \\\\\n",
    "\\frac{dx}{x} = k\\, dt \\\\\n",
    "\\int \\frac{1}{x}\\, dx = \\int k\\, dt \\\\\n",
    "\\log x = kt + c \\\\\n",
    "x = e^{kt+c} \\\\\n",
    "x = e^ce^{kt} \\\\\n",
    "x = c_0e^{kt}\\end{gathered}$$\n",
    "\n",
    "When $t=0$, $x=x_0$. Substitute these to equation above.\n",
    "\n",
    "$$\\begin{gathered}x_0 = c_0e^{k(0)} \\\\\n",
    "x_0 = c_01 \\\\\n",
    "x_0 = c_0 \\\\\n",
    "x = x_0e^{kt}\\end{gathered}$$\n",
    "\n",
    "Using similar math, the solution to the first-order equation \n",
    "\n",
    "$$\\dot{\\mathbf x} = \\mathbf{Ax} ,\\, \\, \\, \\mathbf x(0) = \\mathbf x_0$$\n",
    "\n",
    "where $\\mathbf A$ is a constant matrix, is\n",
    "\n",
    "$$\\mathbf x = e^{\\mathbf At}\\mathbf x_0$$\n",
    "\n",
    "Substituting $F = e^{\\mathbf At}$, we can write \n",
    "\n",
    "$$\\mathbf x_k = \\mathbf F\\mathbf x_{k-1}$$\n",
    "\n",
    "which is the form we are looking for! We have reduced the problem of finding the fundamental matrix to one of finding the value for $e^{\\mathbf At}$.\n",
    "\n",
    "$e^{\\mathbf At}$ is known as the [matrix exponential](https://en.wikipedia.org/wiki/Matrix_exponential). It can be computed with this power series:\n",
    "\n",
    "$$e^{\\mathbf At} = \\mathbf{I} + \\mathbf{A}t  + \\frac{(\\mathbf{A}t)^2}{2!} + \\frac{(\\mathbf{A}t)^3}{3!} + ... $$\n",
    "\n",
    "That series is found by doing a Taylor series expansion of $e^{\\mathbf At}$, which I will not cover here.\n",
    "\n",
    "Let's use this to find the solution to Newton's equations. Using $v$ as a substitution for $\\dot x$, and assuming constant velocity we get the linear matrix-vector form \n",
    "\n",
    "$$\\begin{bmatrix}\\dot x \\\\ \\dot v\\end{bmatrix} =\\begin{bmatrix}0&1\\\\0&0\\end{bmatrix} \\begin{bmatrix}x \\\\ v\\end{bmatrix}$$\n",
    "\n",
    "This is a first order differential equation, so we can set $\\mathbf{A}=\\begin{bmatrix}0&1\\\\0&0\\end{bmatrix}$ and solve the following equation. I have substituted the interval $\\Delta t$ for $t$ to emphasize that the fundamental matrix is discrete:\n",
    "\n",
    "$$\\mathbf F = e^{\\mathbf A\\Delta t} = \\mathbf{I} + \\mathbf A\\Delta t  + \\frac{(\\mathbf A\\Delta t)^2}{2!} + \\frac{(\\mathbf A\\Delta t)^3}{3!} + ... $$\n",
    "\n",
    "If you perform the multiplication you will find that $\\mathbf{A}^2=\\begin{bmatrix}0&0\\\\0&0\\end{bmatrix}$, which means that all higher powers of $\\mathbf{A}$ are also $\\mathbf{0}$. Thus we get an exact answer without an infinite number of terms:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbf F &=\\mathbf{I} + \\mathbf A \\Delta t + \\mathbf{0} \\\\\n",
    "&= \\begin{bmatrix}1&0\\\\0&1\\end{bmatrix} + \\begin{bmatrix}0&1\\\\0&0\\end{bmatrix}\\Delta t\\\\\n",
    "&= \\begin{bmatrix}1&\\Delta t\\\\0&1\\end{bmatrix}\n",
    "\\end{aligned}$$\n",
    "\n",
    "We plug this into $\\mathbf x_k= \\mathbf{Fx}_{k-1}$ to get\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "x_k &=\\begin{bmatrix}1&\\Delta t\\\\0&1\\end{bmatrix}x_{k-1}\n",
    "\\end{aligned}$$\n",
    "\n",
    "You will recognize this as the matrix we derived analytically for the constant velocity Kalman filter in the **Multivariate Kalman Filter** chapter.\n",
    "\n",
    "SciPy's linalg module includes a routine `expm()` to compute the matrix exponential. It does not use the Taylor series method, but the [Padé Approximation](https://en.wikipedia.org/wiki/Pad%C3%A9_approximant). There are many (at least 19) methods to compute the matrix exponential, and all suffer from numerical difficulties[1]. You should be aware of the problems, especially when $\\mathbf A$ is large. If you search for \"pade approximation matrix exponential\" you will find many publications devoted to this problem. \n",
    "\n",
    "In practice this may not be of concern to you as for the Kalman filter we normally just take the first two terms of the Taylor series. But don't assume my treatment of the problem is complete and run off and try to use this technique for other problem without doing a numerical analysis of the performance of this technique. Interestingly, one of the favored ways of solving $e^{\\mathbf At}$ is to use a generalized ode solver. In other words, they do the opposite of what we do - turn $\\mathbf A$ into a set of differential equations, and then solve that set using numerical techniques! \n",
    "\n",
    "Here is an example of using `expm()` to solve $e^{\\mathbf At}$.\n",
    "\n",
    "### 🧠 为什么矩阵指数 $e^{\\mathbf{A}t}$ 只能用于 LTI 系统？\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 首先，什么是矩阵指数？\n",
    "\n",
    "对于一个 LTI 系统：\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}}(t) = \\mathbf{A} \\mathbf{x}(t)\n",
    "$$\n",
    "\n",
    "我们可以写出它的解为：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = e^{\\mathbf{A}t} \\mathbf{x}(0)\n",
    "$$\n",
    "\n",
    "其中矩阵指数的定义为：\n",
    "\n",
    "$$\n",
    "e^{\\mathbf{A}t} = \\sum_{k=0}^{\\infty} \\frac{(\\mathbf{A}t)^k}{k!}\n",
    "$$\n",
    "\n",
    "它是一个**封闭形式的解析解**，用于描述系统状态随时间演化的过程。\n",
    "\n",
    "---\n",
    "\n",
    "### 🛑 为什么这个方法**不能用于 LTV 系统**？\n",
    "\n",
    "如果我们现在有一个 **线性时变系统（LTV）**：\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}}(t) = \\mathbf{A}(t) \\mathbf{x}(t)\n",
    "$$\n",
    "\n",
    "你会发现这个方程更复杂，因为：\n",
    "\n",
    "- 系统矩阵 $\\mathbf{A}(t)$ 是**随时间变化的函数**\n",
    "- 那么在不同时间，系统的行为完全不同（不是常数矩阵）\n",
    "\n",
    "---\n",
    "\n",
    "### ❌ 为什么不能用 $e^{\\mathbf{A}(t)t}$？\n",
    "\n",
    "你可能会问：那我们写成：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = e^{\\mathbf{A}(t)t} \\mathbf{x}(0)\n",
    "$$\n",
    "\n",
    "行不行？\n",
    "\n",
    "答案是 **不行！**\n",
    "\n",
    "因为矩阵指数的定义是基于常数矩阵的：\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt} \\left( e^{\\mathbf{A}t} \\right) = \\mathbf{A} e^{\\mathbf{A}t}\n",
    "$$\n",
    "\n",
    "但如果 $\\mathbf{A}$ 是一个函数 $\\mathbf{A}(t)$，那导数就不是简单的：\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt} \\left( e^{\\mathbf{A}(t)t} \\right) \\neq \\mathbf{A}(t) e^{\\mathbf{A}(t)t}\n",
    "$$\n",
    "\n",
    "实际上，它包含一个非常复杂的求导链式规则，甚至可能**无法用封闭形式表达**。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 那么 LTV 系统怎么求解？\n",
    "\n",
    "LTV 系统的一般解是用所谓的 **状态转移矩阵 $\\Phi(t, t_0)$**：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = \\Phi(t, t_0) \\mathbf{x}(t_0)\n",
    "$$\n",
    "\n",
    "这个 $\\Phi$ **不等于** 简单的 $e^{\\mathbf{A}(t)(t - t_0)}$，而是通过**时间有序积分**得到的：\n",
    "\n",
    "$$\n",
    "\\Phi(t, t_0) = \\mathcal{T} \\exp\\left( \\int_{t_0}^t \\mathbf{A}(\\tau) d\\tau \\right)\n",
    "$$\n",
    "\n",
    "其中 $\\mathcal{T}$ 是**时间有序算符**，表示不同时间点的矩阵乘法**顺序**要考虑在内，这就非常复杂，通常没有解析解，只能用数值方法求解。\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 总结一句话：\n",
    "\n",
    "> 矩阵指数 $e^{\\mathbf{A}t}$ 只能用于 LTI 系统，是因为它假设 $\\mathbf{A}$ 是常数矩阵。而在 LTV 系统中，$\\mathbf{A}(t)$ 随时间变化，导致矩阵指数的性质不再成立，必须使用状态转移矩阵 $\\Phi(t, t_0)$ 和数值方法来求解。\n",
    "\n",
    "\n",
    "### 🧠 What is Padé Approximation?\n",
    "\n",
    "Padé Approximation（帕德近似）是一种比泰勒级数更精确地近似函数的方法，特别适用于需要用**有理函数（分式）**来逼近指数函数的场景。在系统建模和控制理论中，它常用于**近似矩阵指数 $e^{\\mathbf{A} \\Delta t}$**，以得到状态转移矩阵 $\\mathbf{F}$。\n",
    "\n",
    "---\n",
    "\n",
    "### 📌 定义\n",
    "\n",
    "Padé Approximation 是一个有理函数逼近，即：\n",
    "\n",
    "$$\n",
    "e^{x} \\approx \\frac{P(x)}{Q(x)} = \\frac{a_0 + a_1 x + \\dots + a_m x^m}{b_0 + b_1 x + \\dots + b_n x^n}\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $P(x)$ 是分子多项式，次数为 $m$\n",
    "- $Q(x)$ 是分母多项式，次数为 $n$\n",
    "- 系数通过匹配泰勒展开的前几项来求解\n",
    "\n",
    "常用的近似是 $[n/n]$ Padé 近似，即分子和分母多项式次数相等。\n",
    "\n",
    "---\n",
    "\n",
    "### 💡 在控制系统中的应用：近似矩阵指数\n",
    "\n",
    "在离散化连续系统时，我们需要计算：\n",
    "\n",
    "$$\n",
    "\\mathbf{F} = e^{\\mathbf{A} \\Delta t}\n",
    "$$\n",
    "\n",
    "直接计算这个矩阵指数可能比较困难。使用 Padé Approximation 可以把它转化为：\n",
    "\n",
    "$$\n",
    "e^{\\mathbf{A} \\Delta t} \\approx \\left(I - \\frac{1}{2} \\mathbf{A} \\Delta t + \\frac{1}{12} \\mathbf{A}^2 \\Delta t^2 - \\dots \\right)^{-1} \\left(I + \\frac{1}{2} \\mathbf{A} \\Delta t + \\frac{1}{12} \\mathbf{A}^2 \\Delta t^2 + \\dots \\right)\n",
    "$$\n",
    "\n",
    "这是一种比直接截断泰勒展开更稳定、更准确的方法，尤其是在 $\\mathbf{A} \\Delta t$ 比较大的情况下。\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 总结\n",
    "\n",
    "- 帕德近似用一个有理函数来代替指数函数，更准确更稳定\n",
    "- 在 Kalman Filter 中常用于计算 $e^{\\mathbf{A} \\Delta t}$\n",
    "- 是数值计算中处理矩阵指数的经典方法之一\n",
    "\n",
    "需要我举个用 NumPy 实现矩阵 Padé Approximation 的例子吗？\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.linalg import expm\n",
    "\n",
    "dt = 0.1\n",
    "A = np.array([[0, 1], \n",
    "              [0, 0]])\n",
    "expm(A*dt)\n",
    "\n",
    "### Time Invariance\n",
    "\n",
    "If the behavior of the system depends on time we can say that a dynamic system is described by the first-order differential equation\n",
    "\n",
    "$$ g(t) = \\dot x$$\n",
    "\n",
    "However, if the system is *time invariant* the equation is of the form:\n",
    "\n",
    "$$ f(x) = \\dot x$$\n",
    "\n",
    "What does *time invariant* mean? Consider a home stereo. If you input a signal $x$ into it at time $t$, it will output some signal $f(x)$. If you instead perform the input at time $t + \\Delta t$ the output signal will be the same $f(x)$, shifted in time.\n",
    "\n",
    "A counter-example is $x(t) = \\sin(t)$, with the system  $f(x) = t\\,  x(t) = t \\sin(t)$. This is not time invariant; the value will be different at different times due to the multiplication by t.  An aircraft is not time invariant. If you make a control input to the aircraft at a later time its behavior will be different because it will have burned fuel and thus lost weight. Lower weight results in different behavior.\n",
    "\n",
    "We can solve these equations by integrating each side. I demonstrated integrating the time invariant system $v = \\dot x$ above. However, integrating the time invariant equation $\\dot x = f(x)$ is not so straightforward. Using the *separation of variables* techniques we divide by $f(x)$ and move the $dt$ term to the right so we can integrate each side:\n",
    "\n",
    "$$\\begin{gathered}\n",
    "\\frac{dx}{dt} = f(x) \\\\\n",
    "\\int^x_{x_0} \\frac{1}{f(x)} dx = \\int^t_{t_0} dt\n",
    "\\end{gathered}$$\n",
    "\n",
    "If we let $F(x) = \\int \\frac{1}{f(x)} dx$ we get\n",
    "\n",
    "$$F(x) - F(x_0) = t-t_0$$\n",
    "\n",
    "We then solve for x with\n",
    "\n",
    "$$\\begin{gathered}\n",
    "F(x) = t - t_0 + F(x_0) \\\\\n",
    "x = F^{-1}[t-t_0 + F(x_0)]\n",
    "\\end{gathered}$$\n",
    "\n",
    "In other words, we need to find the inverse of $F$. This is not trivial, and a significant amount of coursework in a STEM education is devoted to finding tricky, analytic solutions to this problem. \n",
    "\n",
    "However, they are tricks, and many simple forms of $f(x)$ either have no closed form solution or pose extreme difficulties. Instead, the practicing engineer turns to state-space methods to find approximate solutions.\n",
    "\n",
    "The advantage of the matrix exponential is that we can use it for any arbitrary set of differential equations which are *time invariant*. However, we often use this technique even when the equations are not time invariant. As an aircraft flies it burns fuel and loses weight. However, the weight loss over one second is negligible, and so the system is nearly linear over that time step. Our answers will still be reasonably accurate so long as the time step is short.\n",
    "\n",
    "### 🕒 Time Invariance（时不变性）\n",
    "\n",
    "动态系统如果其行为随时间而变化，我们可以将其描述为如下形式的一阶微分方程：\n",
    "\n",
    "$$\n",
    "\\dot{x} = g(t)\n",
    "$$\n",
    "\n",
    "但如果系统是 **time invariant（时不变的）**，则可以表示为：\n",
    "\n",
    "$$\n",
    "\\dot{x} = f(x)\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 什么是 Time Invariance？\n",
    "\n",
    "时不变性意味着：**系统对输入的响应不依赖于发生的时间，只依赖于输入本身。**\n",
    "\n",
    "举个例子：考虑一个家庭音响。如果你在时间 $t$ 给它一个信号 $x$，它输出信号 $f(x)$。如果你改为在 $t + \\Delta t$ 输入同样的信号 $x$，那么它依旧会输出 $f(x)$，只是**整体时序向后平移了 $\\Delta t$**，输出本身不变。\n",
    "\n",
    "---\n",
    "\n",
    "### ❌ 非时不变系统的反例\n",
    "\n",
    "假设输入为 $x(t) = \\sin(t)$，系统为：\n",
    "\n",
    "$$\n",
    "f(x) = t \\cdot x(t) = t \\cdot \\sin(t)\n",
    "$$\n",
    "\n",
    "这个系统不是时不变的，因为输出依赖于时间 $t$，不同时间点输入同样的信号会得到不同输出。\n",
    "\n",
    "另一个反例是飞机。你在起飞时对其控制和在飞行 1 小时后对其控制，反应会不同，因为飞机变轻了（燃油消耗）。这就不是一个时不变系统。\n",
    "\n",
    "---\n",
    "\n",
    "### 🧮 如何求解时不变微分方程？\n",
    "\n",
    "考虑一个时不变系统：\n",
    "\n",
    "$$\n",
    "\\dot{x} = f(x)\n",
    "$$\n",
    "\n",
    "这不是一个简单线性形式的方程，不能直接积分两边求解。但我们可以使用 **变量分离法（separation of variables）**：\n",
    "\n",
    "$$\n",
    "\\begin{gathered}\n",
    "\\frac{dx}{dt} = f(x) \\\\\n",
    "\\int_{x_0}^{x} \\frac{1}{f(x)} dx = \\int_{t_0}^{t} dt\n",
    "\\end{gathered}\n",
    "$$\n",
    "\n",
    "令：\n",
    "\n",
    "$$\n",
    "F(x) = \\int \\frac{1}{f(x)} dx\n",
    "$$\n",
    "\n",
    "那么结果是：\n",
    "\n",
    "$$\n",
    "F(x) - F(x_0) = t - t_0\n",
    "$$\n",
    "\n",
    "最终解为：\n",
    "\n",
    "$$\n",
    "x = F^{-1}\\left[ t - t_0 + F(x_0) \\right]\n",
    "$$\n",
    "\n",
    "也就是说，我们需要求出 $F$ 的反函数。但这在数学上通常**不容易**，因为很多 $f(x)$ 要么没有封闭解（closed-form solution），要么难以求逆。\n",
    "\n",
    "---\n",
    "\n",
    "### 🤖 工程中的处理方式\n",
    "\n",
    "在实际工程中，我们不会去费劲地求这些解析解，而是用**状态空间方法**来获得近似解。这种方法更通用、可扩展，并且适用于任意维度的微分方程组。\n",
    "\n",
    "特别地，我们会用 **矩阵指数（matrix exponential）** 来解决 **线性时不变系统（LTI）**：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = e^{\\mathbf{A} \\Delta t} \\mathbf{x}(t_0)\n",
    "$$\n",
    "\n",
    "即使在某些非时不变系统中（比如飞机在飞行过程中质量变化），我们也可以认为在**很短的时间步内**系统近似时不变。这样依旧可以使用矩阵指数方法得到足够精确的近似结果。\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 小结\n",
    "\n",
    "- 时不变系统的行为只依赖于输入本身，而非输入发生的时间\n",
    "- 可通过变量分离法积分求解，但难以得到解析解\n",
    "- 实际工程中常用状态空间方法和矩阵指数进行近似计算\n",
    "- 即使非时不变系统，只要时间步足够小，也可以近似使用线性方法处理\n",
    "\n",
    "\n",
    "#### Example: Mass-Spring-Damper Model\n",
    "\n",
    "Suppose we wanted to track the motion of a weight on a spring and connected to a damper, such as an automobile's suspension. The equation for the motion with $m$ being the mass, $k$ the spring constant, and $c$ the damping force, under some input $u$ is \n",
    "\n",
    "$$m\\frac{d^2x}{dt^2} + c\\frac{dx}{dt} +kx = u$$\n",
    "\n",
    "For notational convenience I will write that as\n",
    "\n",
    "$$m\\ddot x + c\\dot x + kx = u$$\n",
    "\n",
    "I can turn this into a system of first order equations by setting $x_1(t)=x(t)$, and then substituting as follows:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "x_1 &= x \\\\\n",
    "x_2 &= \\dot x_1 \\\\\n",
    "\\dot x_2 &= \\ddot x_1 = \\ddot x\n",
    "\\end{aligned}$$\n",
    "\n",
    "As is common I dropped the $(t)$ for notational convenience. This gives the equation\n",
    "\n",
    "$$m\\dot x_2 + c x_2 +kx_1 = u$$\n",
    "\n",
    "Solving for $\\dot x_2$ we get a first order equation:\n",
    "\n",
    "$$\\dot x_2 = -\\frac{c}{m}x_2 - \\frac{k}{m}x_1 + \\frac{1}{m}u$$\n",
    "\n",
    "We put this into matrix form:\n",
    "\n",
    "$$\\begin{bmatrix} \\dot x_1 \\\\ \\dot x_2 \\end{bmatrix} = \n",
    "\\begin{bmatrix}0 & 1 \\\\ -k/m & -c/m \\end{bmatrix}\n",
    "\\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} + \n",
    "\\begin{bmatrix} 0 \\\\ 1/m \\end{bmatrix}u$$\n",
    "\n",
    "Now we use the matrix exponential to find the state transition matrix:\n",
    "\n",
    "$$\\Phi(t) = e^{\\mathbf At} = \\mathbf{I} + \\mathbf At  + \\frac{(\\mathbf At)^2}{2!} + \\frac{(\\mathbf At)^3}{3!} + ... $$\n",
    "\n",
    "The first two terms give us\n",
    "\n",
    "$$\\mathbf F = \\begin{bmatrix}1 & t \\\\ -(k/m) t & 1-(c/m) t \\end{bmatrix}$$\n",
    "\n",
    "This may or may not give you enough precision. You can easily check this by computing $\\frac{(\\mathbf At)^2}{2!}$ for your constants and seeing how much this matrix contributes to the results.\n",
    "\n",
    "### Linear Time Invariant Theory\n",
    "\n",
    "[*Linear Time Invariant Theory*](https://en.wikipedia.org/wiki/LTI_system_theory), also known as LTI System Theory, gives us a way to find $\\Phi$ using the inverse Laplace transform. You are either nodding your head now, or completely lost.  I will not be using the Laplace transform in this book. LTI system theory tells us that \n",
    "\n",
    "$$ \\Phi(t) = \\mathcal{L}^{-1}[(s\\mathbf{I} - \\mathbf{A})^{-1}]$$\n",
    "\n",
    "I have no intention of going into this other than to say that the Laplace transform $\\mathcal{L}$ converts a signal into a space $s$ that excludes time, but finding a solution to the equation above is non-trivial. If you are interested, the Wikipedia article on LTI system theory provides an introduction. I mention LTI because you will find some literature using it to design the Kalman filter matrices for difficult problems. \n",
    "\n",
    "### 🧠 什么是 Linear Time Invariant Theory？（线性时不变系统理论）\n",
    "\n",
    "Linear Time Invariant（LTI）Theory 是研究一类特殊系统的方法，这类系统有两个关键特性：\n",
    "\n",
    "- **Linear（线性）**：输入和输出满足叠加性和比例性\n",
    "- **Time Invariant（时不变）**：系统的行为不会随着时间改变\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 举个简单的例子：\n",
    "\n",
    "假设你有一个系统，比如一个滤波器：\n",
    "\n",
    "- 你输入一个信号 $x(t)$，系统输出 $y(t)$。\n",
    "- 如果你把输入信号延迟 5 秒（变成 $x(t - 5)$），那么输出也只会延迟 5 秒（变成 $y(t - 5)$）。\n",
    "\n",
    "这就说明它是一个 **时不变系统**。\n",
    "\n",
    "---\n",
    "\n",
    "再看“线性”：\n",
    "\n",
    "- 如果输入是两个信号 $x_1(t)$ 和 $x_2(t)$，输出分别是 $y_1(t)$ 和 $y_2(t)$，\n",
    "- 那么输入 $x_1(t) + x_2(t)$，输出就是 $y_1(t) + y_2(t)$；\n",
    "- 输入 $3x_1(t)$，输出就是 $3y_1(t)$。\n",
    "\n",
    "这说明它是一个 **线性系统**。\n",
    "\n",
    "---\n",
    "\n",
    "### 📐 数学模型形式\n",
    "\n",
    "LTI 系统常用的状态空间形式是：\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}}(t) = \\mathbf{A}\\mathbf{x}(t) + \\mathbf{B}\\mathbf{u}(t) \\\\\n",
    "\\mathbf{y}(t) = \\mathbf{C}\\mathbf{x}(t) + \\mathbf{D}\\mathbf{u}(t)\n",
    "$$\n",
    "\n",
    "其中：\n",
    "- $\\mathbf{x}(t)$ 是系统状态\n",
    "- $\\mathbf{u}(t)$ 是输入\n",
    "- $\\mathbf{y}(t)$ 是输出\n",
    "- $\\mathbf{A}, \\mathbf{B}, \\mathbf{C}, \\mathbf{D}$ 是常数矩阵（这也是“时不变”的体现）\n",
    "\n",
    "---\n",
    "\n",
    "### ✨ 为什么 LTI 很重要？\n",
    "\n",
    "- ✅ 方便分析：可以用矩阵指数 $e^{\\mathbf{A}t}$ 来求解\n",
    "- ✅ 可预测：系统不会随时间变“个性”\n",
    "- ✅ 有闭式解：可以用拉普拉斯变换、傅里叶变换等求解\n",
    "- ✅ 用途广：信号处理、控制系统、滤波器、电路、振动分析中都用它\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 总结一句话：\n",
    "\n",
    "**LTI 系统 = 结构简单 + 行为稳定**，非常适合建模和求解，是工程里最常见、最重要的一类系统模型。\n",
    "\n",
    "\n",
    "### 🧠 什么是 Linear Time Variant Theory？（线性时变系统理论）\n",
    "\n",
    "Linear Time Variant（LTV）Theory 是研究**线性但随时间变化的系统**的一套理论。它和 LTI（线性时不变系统）相比，最大的区别就是：**系统的行为随时间变化！**\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 特征定义\n",
    "\n",
    "LTV 系统满足两个条件：\n",
    "\n",
    "- **Linear（线性）**：输入和输出满足叠加性和比例性\n",
    "- **Time Variant（时变）**：系统的参数随时间而变\n",
    "\n",
    "---\n",
    "\n",
    "### 📐 数学表达式\n",
    "\n",
    "一个典型的 LTV 系统可以写成状态空间的形式如下：\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}}(t) = \\mathbf{A}(t)\\mathbf{x}(t) + \\mathbf{B}(t)\\mathbf{u}(t) \\\\\n",
    "\\mathbf{y}(t) = \\mathbf{C}(t)\\mathbf{x}(t) + \\mathbf{D}(t)\\mathbf{u}(t)\n",
    "$$\n",
    "\n",
    "你可以看到，系统的矩阵 $\\mathbf{A}(t), \\mathbf{B}(t), \\mathbf{C}(t), \\mathbf{D}(t)$ 都是 **随时间变化的函数**，而不像 LTI 系统中是常数。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔍 举个例子\n",
    "\n",
    "假设一辆汽车在平路上开，质量是 $1000kg$，加速度和油门成正比。那是个 LTI 系统。\n",
    "\n",
    "但如果这辆车在行驶过程中不断减轻（比如燃油消耗或载重变化），那它的响应特性会变。这个系统的“质量”就是随时间变化的参数，所以它就是一个 **LTV 系统**。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔄 LTI vs LTV 对比表\n",
    "\n",
    "| 特性         | LTI 系统                    | LTV 系统                     |\n",
    "|--------------|-----------------------------|------------------------------|\n",
    "| 参数是否变   | 不变（常数）                | 随时间变化                   |\n",
    "| 解的难度     | 容易，有封闭解               | 较难，通常需要数值解法       |\n",
    "| 常见求解方法 | 矩阵指数、拉普拉斯变换等    | 数值积分、变换基等           |\n",
    "| 实例         | 电路、电机、滤波器等         | 飞机、航天器、机器人等动态变化系统 |\n",
    "\n",
    "---\n",
    "\n",
    "### 🚀 为什么要学 LTV 系统？\n",
    "\n",
    "- ✅ 更贴近真实世界：很多系统参数都会随时间变化，比如飞机飞行过程中的重量、电池电量变化等\n",
    "- ✅\n",
    "\n",
    "\n",
    "### 🧠 为什么矩阵指数 $e^{\\mathbf{A}t}$ 只能用于 LTI 系统？\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 首先，什么是矩阵指数？\n",
    "\n",
    "对于一个 LTI 系统：\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}}(t) = \\mathbf{A} \\mathbf{x}(t)\n",
    "$$\n",
    "\n",
    "我们可以写出它的解为：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = e^{\\mathbf{A}t} \\mathbf{x}(0)\n",
    "$$\n",
    "\n",
    "其中矩阵指数的定义为：\n",
    "\n",
    "$$\n",
    "e^{\\mathbf{A}t} = \\sum_{k=0}^{\\infty} \\frac{(\\mathbf{A}t)^k}{k!}\n",
    "$$\n",
    "\n",
    "它是一个**封闭形式的解析解**，用于描述系统状态随时间演化的过程。\n",
    "\n",
    "---\n",
    "\n",
    "### 🛑 为什么这个方法**不能用于 LTV 系统**？\n",
    "\n",
    "如果我们现在有一个 **线性时变系统（LTV）**：\n",
    "\n",
    "$$\n",
    "\\dot{\\mathbf{x}}(t) = \\mathbf{A}(t) \\mathbf{x}(t)\n",
    "$$\n",
    "\n",
    "你会发现这个方程更复杂，因为：\n",
    "\n",
    "- 系统矩阵 $\\mathbf{A}(t)$ 是**随时间变化的函数**\n",
    "- 那么在不同时间，系统的行为完全不同（不是常数矩阵）\n",
    "\n",
    "---\n",
    "\n",
    "### ❌ 为什么不能用 $e^{\\mathbf{A}(t)t}$？\n",
    "\n",
    "你可能会问：那我们写成：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = e^{\\mathbf{A}(t)t} \\mathbf{x}(0)\n",
    "$$\n",
    "\n",
    "行不行？\n",
    "\n",
    "答案是 **不行！**\n",
    "\n",
    "因为矩阵指数的定义是基于常数矩阵的：\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt} \\left( e^{\\mathbf{A}t} \\right) = \\mathbf{A} e^{\\mathbf{A}t}\n",
    "$$\n",
    "\n",
    "但如果 $\\mathbf{A}$ 是一个函数 $\\mathbf{A}(t)$，那导数就不是简单的：\n",
    "\n",
    "$$\n",
    "\\frac{d}{dt} \\left( e^{\\mathbf{A}(t)t} \\right) \\neq \\mathbf{A}(t) e^{\\mathbf{A}(t)t}\n",
    "$$\n",
    "\n",
    "实际上，它包含一个非常复杂的求导链式规则，甚至可能**无法用封闭形式表达**。\n",
    "\n",
    "---\n",
    "\n",
    "### 🔧 那么 LTV 系统怎么求解？\n",
    "\n",
    "LTV 系统的一般解是用所谓的 **状态转移矩阵 $\\Phi(t, t_0)$**：\n",
    "\n",
    "$$\n",
    "\\mathbf{x}(t) = \\Phi(t, t_0) \\mathbf{x}(t_0)\n",
    "$$\n",
    "\n",
    "这个 $\\Phi$ **不等于** 简单的 $e^{\\mathbf{A}(t)(t - t_0)}$，而是通过**时间有序积分**得到的：\n",
    "\n",
    "$$\n",
    "\\Phi(t, t_0) = \\mathcal{T} \\exp\\left( \\int_{t_0}^t \\mathbf{A}(\\tau) d\\tau \\right)\n",
    "$$\n",
    "\n",
    "其中 $\\mathcal{T}$ 是**时间有序算符**，表示不同时间点的矩阵乘法**顺序**要考虑在内，这就非常复杂，通常没有解析解，只能用数值方法求解。\n",
    "\n",
    "---\n",
    "\n",
    "### ✅ 总结一句话：\n",
    "\n",
    "> 矩阵指数 $e^{\\mathbf{A}t}$ 只能用于 LTI 系统，是因为它假设 $\\mathbf{A}$ 是常数矩阵。而在 LTV 系统中，$\\mathbf{A}(t)$ 随时间变化，导致矩阵指数的性质不再成立，必须使用状态转移矩阵 $\\Phi(t, t_0)$ 和数值方法来求解。\n",
    "\n",
    "\n",
    "### Numerical Solutions\n",
    "\n",
    "Finally, there are numerical techniques to find $\\mathbf F$. As filters get larger finding analytical solutions becomes very tedious (though packages like SymPy make it easier). C. F. van Loan [2] has developed a technique that finds both $\\Phi$ and $\\mathbf Q$ numerically. Given the continuous model\n",
    "\n",
    "$$ \\dot x = Ax + Gw$$\n",
    "\n",
    "where $w$ is the unity white noise, van Loan's method computes both $\\mathbf F_k$ and $\\mathbf Q_k$.\n",
    "    \n",
    "I have implemented van Loan's method in `FilterPy`. You may use it as follows:\n",
    "\n",
    "```python\n",
    "from filterpy.common import van_loan_discretization\n",
    "\n",
    "A = np.array([[0., 1.], [-1., 0.]])\n",
    "G = np.array([[0.], [2.]]) # white noise scaling\n",
    "F, Q = van_loan_discretization(A, G, dt=0.1)\n",
    "```\n",
    "    \n",
    "In the section *Numeric Integration of Differential Equations* I present alternative methods which are very commonly used in Kalman filtering.\n",
    "\n",
    "## Design of the Process Noise Matrix\n",
    "\n",
    "In general the design of the $\\mathbf Q$ matrix is among the most difficult aspects of Kalman filter design. This is due to several factors. First, the math requires a good foundation in signal theory. Second, we are trying to model the noise in something for which we have little information. Consider trying to model the process noise for a thrown baseball. We can model it as a sphere moving through the air, but that leaves many unknown factors - ball rotation and spin decay, the coefficient of drag of a ball with stitches, the effects of wind and air density, and so on. We develop the equations for an exact mathematical solution for a given process model, but since the process model is incomplete the result for $\\mathbf Q$ will also be incomplete. This has a lot of ramifications for the behavior of the Kalman filter. If $\\mathbf Q$ is too small then the filter will be overconfident in its prediction model and will diverge from the actual solution. If $\\mathbf Q$ is too large than the filter will be unduly influenced by the noise in the measurements and perform sub-optimally. In practice we spend a lot of time running simulations and evaluating collected data to try to select an appropriate value for $\\mathbf Q$. But let's start by looking at the math.\n",
    "\n",
    "\n",
    "Let's assume a kinematic system - some system that can be modeled using Newton's equations of motion. We can make a few different assumptions about this process. \n",
    "\n",
    "We have been using a process model of\n",
    "\n",
    "$$ \\dot{\\mathbf x} = \\mathbf{Ax} + \\mathbf{Bu} + \\mathbf{w}$$\n",
    "\n",
    "where $\\mathbf{w}$ is the process noise. Kinematic systems are *continuous* - their inputs and outputs can vary at any arbitrary point in time. However, our Kalman filters are *discrete* (there are continuous forms for Kalman filters, but we do not cover them in this book). We sample the system at regular intervals. Therefore we must find the discrete representation for the noise term in the equation above. This depends on what assumptions we make about the behavior of the noise. We will consider two different models for the noise.\n",
    "\n",
    "### Continuous White Noise Model\n",
    "\n",
    "We model kinematic systems using Newton's equations. We have either used position and velocity, or position, velocity, and acceleration as the models for our systems. There is nothing stopping us from going further - we can model jerk, jounce, snap, and so on. We don't do that normally because adding terms beyond the dynamics of the real system degrades the estimate. \n",
    "\n",
    "Let's say that we need to model the position, velocity, and acceleration. We can then assume that acceleration is constant for each discrete time step. Of course, there is process noise in the system and so the acceleration is not actually constant. The tracked object will alter the acceleration over time due to external, unmodeled forces. In this section we will assume that the acceleration changes by a continuous time zero-mean white noise $w(t)$. In other words, we are assuming that the small changes in velocity average to 0 over time (zero-mean). \n",
    "\n",
    "Since the noise is changing continuously we will need to integrate to get the discrete noise for the discretization interval that we have chosen. We will not prove it here, but the equation for the discretization of the noise is\n",
    "\n",
    "$$\\mathbf Q = \\int_0^{\\Delta t} \\mathbf F(t)\\mathbf{Q_c}\\mathbf F^\\mathsf{T}(t) dt$$\n",
    "\n",
    "where $\\mathbf{Q_c}$ is the continuous noise. The general reasoning should be clear. $\\mathbf F(t)\\mathbf{Q_c}\\mathbf F^\\mathsf{T}(t)$ is a projection of the continuous noise based on our process model $\\mathbf F(t)$ at the instant $t$. We want to know how much noise is added to the system over a discrete intervat $\\Delta t$, so we integrate this expression over the interval $[0, \\Delta t]$. \n",
    "\n",
    "We know the fundamental matrix for Newtonian systems is\n",
    "\n",
    "$$F = \\begin{bmatrix}1 & \\Delta t & {\\Delta t}^2/2 \\\\ 0 & 1 & \\Delta t\\\\ 0& 0& 1\\end{bmatrix}$$\n",
    "\n",
    "We define the continuous noise as \n",
    "\n",
    "$$\\mathbf{Q_c} = \\begin{bmatrix}0&0&0\\\\0&0&0\\\\0&0&1\\end{bmatrix} \\Phi_s$$\n",
    "\n",
    "where $\\Phi_s$ is the spectral density of the white noise. This can be derived, but is beyond the scope of this book. See any standard text on stochastic processes for the details. In practice we often do not know the spectral density of the noise, and so this turns into an \"engineering\" factor - a number we experimentally tune until our filter performs as we expect. You can see that the matrix that $\\Phi_s$ is multiplied by effectively assigns the power spectral density to the acceleration term. This makes sense; we assume that the system has constant acceleration except for the variations caused by noise. The noise alters the acceleration.\n",
    "\n",
    "We could carry out these computations ourselves, but I prefer using SymPy to solve the equation.\n",
    "\n",
    "$$\\mathbf{Q_c} = \\begin{bmatrix}0&0&0\\\\0&0&0\\\\0&0&1\\end{bmatrix} \\Phi_s$$\n",
    "\n",
    "\n",
    "\n",
    "import sympy\n",
    "from sympy import (init_printing, Matrix, MatMul, \n",
    "                   integrate, symbols)\n",
    "\n",
    "init_printing(use_latex='mathjax')\n",
    "dt, phi = symbols('\\Delta{t} \\Phi_s')\n",
    "F_k = Matrix([[1, dt, dt**2/2],\n",
    "              [0,  1,      dt],\n",
    "              [0,  0,       1]])\n",
    "Q_c = Matrix([[0, 0, 0],\n",
    "              [0, 0, 0],\n",
    "              [0, 0, 1]])*phi\n",
    "\n",
    "Q = integrate(F_k * Q_c * F_k.T, (dt, 0, dt))\n",
    "\n",
    "# factor phi out of the matrix to make it more readable\n",
    "Q = Q / phi\n",
    "MatMul(Q, phi)\n",
    "\n",
    "For completeness, let us compute the equations for the 0th order and 1st order equations.\n",
    "\n",
    "F_k = Matrix([[1]])\n",
    "Q_c = Matrix([[phi]])\n",
    "\n",
    "print('0th order discrete process noise')\n",
    "integrate(F_k*Q_c*F_k.T,(dt, 0, dt))\n",
    "\n",
    "F_k = Matrix([[1, dt],\n",
    "              [0, 1]])\n",
    "Q_c = Matrix([[0, 0],\n",
    "              [0, 1]]) * phi\n",
    "\n",
    "Q = integrate(F_k * Q_c * F_k.T, (dt, 0, dt))\n",
    "\n",
    "print('1st order discrete process noise')\n",
    "# factor phi out of the matrix to make it more readable\n",
    "Q = Q / phi\n",
    "MatMul(Q, phi)\n",
    "\n",
    "### Piecewise White Noise Model\n",
    "\n",
    "Another model for the noise assumes that the that highest order term (say, acceleration) is constant for the duration of each time period, but differs for each time period, and each of these is uncorrelated between time periods. In other words there is a discontinuous jump in acceleration at each time step. This is subtly different than the model above, where we assumed that the last term had a continuously varying noisy signal applied to it.  \n",
    "\n",
    "We will model this as\n",
    "\n",
    "$$f(x)=Fx+\\Gamma w$$\n",
    "\n",
    "where $\\Gamma$ is the *noise gain* of the system, and $w$ is the constant piecewise acceleration (or velocity, or jerk, etc). \n",
    "\n",
    "Let's start by looking at a first order system. In this case we have the state transition function\n",
    "\n",
    "$$\\mathbf{F} = \\begin{bmatrix}1&\\Delta t \\\\ 0& 1\\end{bmatrix}$$\n",
    "\n",
    "In one time period, the change in velocity will be $w(t)\\Delta t$, and the change in position will be $w(t)\\Delta t^2/2$, giving us\n",
    "\n",
    "$$\\Gamma = \\begin{bmatrix}\\frac{1}{2}\\Delta t^2 \\\\ \\Delta t\\end{bmatrix}$$\n",
    "\n",
    "The covariance of the process noise is then\n",
    "\n",
    "$$Q = \\mathbb E[\\Gamma w(t) w(t) \\Gamma^\\mathsf{T}] = \\Gamma\\sigma^2_v\\Gamma^\\mathsf{T}$$.\n",
    "\n",
    "We can compute that with SymPy as follows\n",
    "\n",
    "var = symbols('sigma^2_v')\n",
    "v = Matrix([[dt**2 / 2], [dt]])\n",
    "\n",
    "Q = v * var * v.T\n",
    "\n",
    "# factor variance out of the matrix to make it more readable\n",
    "Q = Q / var\n",
    "MatMul(Q, var)\n",
    "\n",
    "The second order system proceeds with the same math.\n",
    "\n",
    "\n",
    "$$\\mathbf{F} = \\begin{bmatrix}1 & \\Delta t & {\\Delta t}^2/2 \\\\ 0 & 1 & \\Delta t\\\\ 0& 0& 1\\end{bmatrix}$$\n",
    "\n",
    "Here we will assume that the white noise is a discrete time Wiener process. This gives us\n",
    "\n",
    "$$\\Gamma = \\begin{bmatrix}\\frac{1}{2}\\Delta t^2 \\\\ \\Delta t\\\\ 1\\end{bmatrix}$$\n",
    "\n",
    "There is no 'truth' to this model, it is just convenient and provides good results. For example, we could assume that the noise is applied to the jerk at the cost of a more complicated equation. \n",
    "\n",
    "The covariance of the process noise is then\n",
    "\n",
    "$$Q = \\mathbb E[\\Gamma w(t) w(t) \\Gamma^\\mathsf{T}] = \\Gamma\\sigma^2_v\\Gamma^\\mathsf{T}$$.\n",
    "\n",
    "We can compute that with SymPy as follows\n",
    "\n",
    "var = symbols('sigma^2_v')\n",
    "v = Matrix([[dt**2 / 2], [dt], [1]])\n",
    "\n",
    "Q = v * var * v.T\n",
    "\n",
    "# factor variance out of the matrix to make it more readable\n",
    "Q = Q / var\n",
    "MatMul(Q, var)\n",
    "\n",
    "We cannot say that this model is more or less correct than the continuous model - both are approximations to what is happening to the actual object. Only experience and experiments can guide you to the appropriate model. In practice you will usually find that either model provides reasonable results, but typically one will perform better than the other.\n",
    "\n",
    "The advantage of the second model is that we can model the noise in terms of $\\sigma^2$ which we can describe in terms of the motion and the amount of error we expect. The first model requires us to specify the spectral density, which is not very intuitive, but it handles varying time samples much more easily since the noise is integrated across the time period. However, these are not fixed rules - use whichever model (or a model of your own devising) based on testing how the filter performs and/or your knowledge of the behavior of the physical model.\n",
    "\n",
    "A good rule of thumb is to set $\\sigma$ somewhere from $\\frac{1}{2}\\Delta a$ to $\\Delta a$, where $\\Delta a$ is the maximum amount that the acceleration will change between sample periods. In practice we pick a number, run simulations on data, and choose a value that works well.\n",
    "\n",
    "### Using FilterPy to Compute Q\n",
    "\n",
    "FilterPy offers several routines to compute the $\\mathbf Q$ matrix. The function `Q_continuous_white_noise()` computes $\\mathbf Q$ for a given value for $\\Delta t$ and the spectral density.\n",
    "\n",
    "from filterpy.common import Q_continuous_white_noise\n",
    "from filterpy.common import Q_discrete_white_noise\n",
    "\n",
    "Q = Q_continuous_white_noise(dim=2, dt=1, spectral_density=1)\n",
    "print(Q)\n",
    "\n",
    "Q = Q_continuous_white_noise(dim=3, dt=1, spectral_density=1)\n",
    "print(Q)\n",
    "\n",
    "The function `Q_discrete_white_noise()` computes $\\mathbf Q$ assuming a piecewise model for the noise.\n",
    "\n",
    "Q = Q_discrete_white_noise(2, var=1.)\n",
    "print(Q)\n",
    "\n",
    "Q = Q_discrete_white_noise(3, var=1.)\n",
    "print(Q)\n",
    "\n",
    "### Simplification of Q\n",
    "\n",
    "Many treatments use a much simpler form for $\\mathbf Q$, setting it to zero except for a noise term in the lower rightmost element. Is this justified? Well, consider the value of $\\mathbf Q$ for a small $\\Delta t$\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(precision=8)\n",
    "Q = Q_continuous_white_noise(\n",
    "    dim=3, dt=0.05, spectral_density=1)\n",
    "print(Q)\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "We can see that most of the terms are very small. Recall that the only equation using this matrix is\n",
    "\n",
    "$$ \\mathbf P=\\mathbf{FPF}^\\mathsf{T} + \\mathbf Q$$\n",
    "\n",
    "If the values for $\\mathbf Q$ are small relative to $\\mathbf P$\n",
    "then it will be contributing almost nothing to the computation of $\\mathbf P$. Setting $\\mathbf Q$ to the zero matrix except for the lower right term\n",
    "\n",
    "$$\\mathbf Q=\\begin{bmatrix}0&0&0\\\\0&0&0\\\\0&0&\\sigma^2\\end{bmatrix}$$\n",
    "\n",
    "while not correct, is often a useful approximation. If you do this for an important application you will have to perform quite a few studies to guarantee that your filter works in a variety of situations. \n",
    "\n",
    "If you do this, 'lower right term' means the most rapidly changing term for each variable. If the state is $x=\\begin{bmatrix}x & \\dot x & \\ddot{x} & y & \\dot{y} & \\ddot{y}\\end{bmatrix}^\\mathsf{T}$ Then $\\mathbf Q$ will be 6x6; the elements for both $\\ddot{x}$ and $\\ddot{y}$ will have to be set to non-zero in $\\mathbf Q$.\n",
    "\n",
    "## Stable Compution of the Posterior Covariance\n",
    "\n",
    "I've presented the equation to compute the posterior covariance as\n",
    "\n",
    "$$\\mathbf P = (\\mathbf I - \\mathbf{KH})\\mathbf{\\bar P}$$\n",
    "\n",
    "and while strictly speaking this is correct, this is not how I compute it in `FilterPy`, where I use the *Joseph* equation\n",
    "\n",
    "\n",
    "$$\\mathbf P = (\\mathbf I-\\mathbf {KH})\\mathbf{\\bar P}(\\mathbf I-\\mathbf{KH})^\\mathsf T + \\mathbf{KRK}^\\mathsf T$$\n",
    "\n",
    "\n",
    "I frequently get emails and/or GitHub issues raised, claiming the implementation is a bug. It is not a bug, and I use it for several reasons. First, the subtraction $(\\mathbf I - \\mathbf{KH})$ can lead to nonsymmetric matrix results due to floating point errors. Covariances must be symmetric, and so becoming nonsymmetric usually leads to the Kalman filter diverging, or even for the code to raise an exception because of the checks built into `NumPy`.\n",
    "\n",
    "A traditional way to preserve symmetry is the following formula:\n",
    "\n",
    "$$\\mathbf P = (\\mathbf P + \\mathbf P^\\mathsf T) / 2$$\n",
    "\n",
    "This is safe because $\\sigma_{ij} = \\sigma_{ji}$ for all covariances in the matrix. Hence this operation averages the error between the differences of the two values if they have diverged due to floating point errors. \n",
    "\n",
    "If you look at the Joseph form for the equation above, you'll see there is a similar $\\mathbf{ABA}^\\mathsf T$ pattern in both terms. So they both preserve symmetry. But where did this equation come from, and why do I use it instead of\n",
    "\n",
    "\n",
    "$$\\mathbf P = (\\mathbf I - \\mathbf{KH})\\mathbf{\\bar P} \\\\\n",
    "\\mathbf P = (\\mathbf P + \\mathbf P^\\mathsf T) / 2$$\n",
    "\n",
    "\n",
    "Let's just derive the equation from first principles. It's not too bad, and you need to understand the derivation to understand the purpose of the equation, and, more importantly, diagnose issues if your filter diverges due to numerical instability. This derivation comes from Brown[4].\n",
    "\n",
    "First, some symbology. $\\mathbf x$ is the true state of our system. $\\mathbf{\\hat x}$ is the estimated state of our system - the posterior. And $\\mathbf{\\bar x}$ is the estimated prior of the system. \n",
    "\n",
    "\n",
    "Given that, we can define our model to be\n",
    "\n",
    "$$\\mathbf x_{k+1} = \\mathbf F_k \\mathbf x_k + \\mathbf w_k \\\\\n",
    "\\mathbf z_k = \\mathbf H_k \\mathbf x_k + \\mathbf v_k$$\n",
    "\n",
    "In words, the next state $\\mathbf x_{k+1}$ of the system is the current state $k$ moved by some process $\\mathbf F_k$ plus some noise $\\mathbf w_k$. \n",
    "\n",
    "Note that these are definitions. No system perfectly follows a mathematical model, so we model that with the noise term $\\mathbf w_k$. And no measurement is perfect due to sensor error, so we model that with $\\mathbf v_k$\n",
    "\n",
    "I'll dispense with the subscript $k$ since in the remainder of the derivation we will only consider values at step $k$, never step $k+1$.\n",
    "\n",
    "Now we define the estimation error as the difference between the true state and the estimated state\n",
    "\n",
    "$$ \\mathbf e = \\mathbf x - \\mathbf{\\hat x}$$\n",
    "\n",
    "Again, this is a definition; we don't know how to compute $\\mathbf e$, it is just the defined difference between the true and estimated state.\n",
    "\n",
    "This allows us to define the covariance of our estimate, which is defined as the expected value of $\\mathbf{ee}^\\mathsf T$:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "P &= E[\\mathbf{ee}^\\mathsf T] \\\\\n",
    "&= E[(\\mathbf x - \\mathbf{\\hat x})(\\mathbf x - \\mathbf{\\hat x})^\\mathsf T]\n",
    "\\end{aligned}$$\n",
    "\n",
    "\n",
    "Next, we define the posterior estimate as\n",
    "\n",
    "$$\\mathbf {\\hat x} = \\mathbf{\\bar x} + \\mathbf K(\\mathbf z - \\mathbf{H \\bar x})$$\n",
    "\n",
    "That looks like the equation from the Kalman filter, and for good reason. But as with the rest of the math so far, this is a **definition**. In particular, we have not defined $\\mathbf K$, and you shouldn't think of it as the Kalman gain, because we are solving this for *any* problem, not just for linear Kalman filters. Here, $\\mathbf K$ is just some unspecified blending value between 0 and 1.\n",
    "\n",
    "Now we have our definitions, let's perform some substitution and algebra.\n",
    "\n",
    "The term $(\\mathbf x - \\mathbf{\\hat x})$ can be expanded by replacing $\\mathbf{\\hat x}$ with the definition above, yielding\n",
    "\n",
    "$$(\\mathbf x - \\mathbf{\\hat x}) = \\mathbf x - (\\mathbf{\\bar x} + \\mathbf K(\\mathbf z - \\mathbf{H \\bar x}))$$\n",
    "\n",
    "Now we replace $\\mathbf z$ with $\\mathbf H \\mathbf x + \\mathbf v$:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "(\\mathbf x - \\mathbf{\\hat x})\n",
    "&= \\mathbf x - (\\mathbf{\\bar x} + \\mathbf K(\\mathbf z - \\mathbf{H \\bar x})) \\\\\n",
    "&= \\mathbf x - (\\mathbf{\\bar x} + \\mathbf K(\\mathbf H \\mathbf x + \\mathbf v - \\mathbf{H \\bar x})) \\\\\n",
    "&= (\\mathbf x - \\mathbf{\\bar x}) - \\mathbf K(\\mathbf H \\mathbf x + \\mathbf v - \\mathbf{H \\bar x}) \\\\\n",
    "&= (\\mathbf x - \\mathbf{\\bar x}) - \\mathbf{KH}(\\mathbf x - \\mathbf{ \\bar x}) - \\mathbf{Kv} \\\\\n",
    "&=  (\\mathbf I - \\mathbf{KH})(\\mathbf x - \\mathbf{\\bar x}) - \\mathbf{Kv}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Now we can solve for $\\mathbf P$ if we note that the expected value of $(\\mathbf x - \\mathbf{\\bar x})$ is the prior covariance $\\mathbf{\\bar P}$, and that the expected value of $\\mathbf v$ is $E[\\mathbf{vv}^\\mathbf T] = \\mathbf R$:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\mathbf P &= \n",
    "   E\\big[[(\\mathbf I - \\mathbf{KH})(\\mathbf x - \\mathbf{\\bar x}) - \\mathbf{Kv})]\n",
    "  [(\\mathbf I - \\mathbf{KH})(\\mathbf x - \\mathbf{\\bar x}) - \\mathbf{Kv}]^\\mathsf T\\big ] \\\\\n",
    "  &= (\\mathbf I - \\mathbf{KH})\\mathbf{\\bar P}(\\mathbf I - \\mathbf{KH})^\\mathsf T + \\mathbf{KRK}^\\mathsf T\n",
    "\\end{aligned}$$\n",
    "\n",
    "which is what we came here to prove.\n",
    "\n",
    "Note that this equation is valid for *any* $\\mathbf K$, not just the optimal $\\mathbf K$ computed by the Kalman filter. And that is why I use this equation. In practice the Kalman gain computed by the filter is *not* the optimal value both because the real world is never truly linear and Gaussian, and because of floating point errors induced by computation. This equation is far less likely to cause the Kalman filter to diverge in the face of real world conditions.\n",
    "\n",
    "Where did $\\mathbf P = (\\mathbf I - \\mathbf{KH})\\mathbf{\\bar P}$ come from, then? Let's finish the derivation, which is simple. Recall that the Kalman filter (optimal) gain is given by\n",
    "\n",
    "$$\\mathbf K = \\mathbf{\\bar P H^\\mathsf T}(\\mathbf{H \\bar P H}^\\mathsf T + \\mathbf R)^{-1}$$\n",
    "\n",
    "Now we substitute this into the equation we just derived:\n",
    "\n",
    "$$\\begin{aligned}\n",
    "&= (\\mathbf I - \\mathbf{KH})\\mathbf{\\bar P}(\\mathbf I - \\mathbf{KH})^\\mathsf T + \\mathbf{KRK}^\\mathsf T\\\\\n",
    "&= \\mathbf{\\bar P} - \\mathbf{KH}\\mathbf{\\bar P} - \\mathbf{\\bar PH}^\\mathsf T\\mathbf{K}^\\mathsf T + \\mathbf K(\\mathbf{H \\bar P H}^\\mathsf T + \\mathbf R)\\mathbf K^\\mathsf T \\\\\n",
    "&= \\mathbf{\\bar P} - \\mathbf{KH}\\mathbf{\\bar P} - \\mathbf{\\bar PH}^\\mathsf T\\mathbf{K}^\\mathsf T + \\mathbf{\\bar P H^\\mathsf T}(\\mathbf{H \\bar P H}^\\mathsf T + \\mathbf R)^{-1}(\\mathbf{H \\bar P H}^\\mathsf T + \\mathbf R)\\mathbf K^\\mathsf T\\\\\n",
    "&= \\mathbf{\\bar P} - \\mathbf{KH}\\mathbf{\\bar P} - \\mathbf{\\bar PH}^\\mathsf T\\mathbf{K}^\\mathsf T + \\mathbf{\\bar P H^\\mathsf T}\\mathbf K^\\mathsf T\\\\\n",
    "&= \\mathbf{\\bar P} - \\mathbf{KH}\\mathbf{\\bar P}\\\\\n",
    "&= (\\mathbf I - \\mathbf{KH})\\mathbf{\\bar P}\n",
    "\\end{aligned}$$\n",
    "\n",
    "Therefore $\\mathbf P = (\\mathbf I - \\mathbf{KH})\\mathbf{\\bar P}$ is mathematically correct when the gain is optimal, but so is $(\\mathbf I - \\mathbf{KH})\\mathbf{\\bar P}(\\mathbf I - \\mathbf{KH})^\\mathsf T + \\mathbf{KRK}^\\mathsf T$. As we already discussed the latter is also correct when the gain is suboptimal, and it is also more numerically stable. Therefore I use this computation in FilterPy.\n",
    "\n",
    "It is quite possible that your filter still diverges, especially if it runs for hundreds or thousands of epochs. You will need to examine these equations. The literature provides yet other forms of this computation which may be more applicable to your problem. As always, if you are solving real engineering problems where failure could mean loss of equipment or life, you will need to move past this book and into the engineering literature. If you are working with 'toy' problems where failure is not damaging, if you detect divergence you can just reset the value of $\\mathbf P$ to some 'reasonable' value and keep on going. For example, you could zero out the non diagonal elements so the matrix only contains variances, and then maybe multiply by a constant somewhat larger than one to reflect the loss of information you just injected into the filter. Use your imagination, and test.\n",
    "\n",
    "## Deriving the Kalman Gain Equation\n",
    "\n",
    "If you read the last section, you might as well read this one. With this we will have derived the Kalman filter equations.\n",
    "\n",
    "Note that this derivation is *not* using Bayes equations. I've seen at least four different ways to derive the Kalman filter equations; this derivation is typical to the literature, and follows from the last section. The source is again Brown [4].\n",
    "\n",
    "In the last section we used an unspecified scaling factor $\\mathbf K$ to derive the Joseph form of the covariance equation. If we want an optimal filter, we need to use calculus to minimize the errors in the equations. You should be familiar with this idea. If you want to find the minimum value of a function $f(x)$, you take the derivative and set it equal to zero: $\\frac{x}{dx}f(x) = 0$.\n",
    "\n",
    "In our problem the error is expressed by the covariance matrix $\\mathbf P$. In particular, the diagonal expresses the error (variance) of each element in the state vector. So, to find the optimal gain we want to take the derivative of the trace (sum) of the diagonal.\n",
    "\n",
    "Brown reminds us of two formulas involving the derivative of traces:\n",
    "\n",
    "$$\\frac{d\\, trace(\\mathbf{AB})}{d\\mathbf A} = \\mathbf B^\\mathsf T$$\n",
    "\n",
    "$$\\frac{d\\, trace(\\mathbf{ACA}^\\mathsf T)}{d\\mathbf A} = 2\\mathbf{AC}$$\n",
    "\n",
    "where $\\mathbf{AB}$ is square and $\\mathbf C$ is symmetric.\n",
    "\n",
    "\n",
    "We expand out the Joseph equation to:\n",
    "\n",
    "$$\\mathbf P = \\mathbf{\\bar P} - \\mathbf{KH}\\mathbf{\\bar P} - \\mathbf{\\bar P}\\mathbf H^\\mathsf T \\mathbf K^\\mathsf T + \\mathbf K(\\mathbf H \\mathbf{\\bar P}\\mathbf H^\\mathsf T + \\mathbf R)\\mathbf K^\\mathsf T$$\n",
    "\n",
    "Now we need to the the derivative of the trace of $\\mathbf P$ with respect to $\\mathbf K$: $\\frac{d\\, trace(\\mathbf P)}{d\\mathbf K}$.\n",
    "\n",
    "The derivative of the trace the first term with respect to $\\mathbf K$ is $0$, since it does not have $\\mathbf K$ in the expression.\n",
    "\n",
    "The derivative of the trace of the second term is $(\\mathbf H\\mathbf{\\bar P})^\\mathsf T$.\n",
    "\n",
    "We can find the derivative of the trace of the third term by noticing that $\\mathbf{\\bar P}\\mathbf H^\\mathsf T \\mathbf K^\\mathsf T$ is the transpose of $\\mathbf{KH}\\mathbf{\\bar P}$. The trace of a matrix is equal to the trace of it's transpose, so it's derivative will be same as the second term.\n",
    "\n",
    "Finally, the derivative of the trace of the fourth term is $2\\mathbf K(\\mathbf H \\mathbf{\\bar P}\\mathbf H^\\mathsf T + \\mathbf R)$.\n",
    "\n",
    "This gives us the final value of \n",
    "\n",
    "$$\\frac{d\\, trace(\\mathbf P)}{d\\mathbf K} = -2(\\mathbf H\\mathbf{\\bar P})^\\mathsf T + 2\\mathbf K(\\mathbf H \\mathbf{\\bar P}\\mathbf H^\\mathsf T + \\mathbf R)$$\n",
    "\n",
    "We set this to zero and solve to find the equation for $\\mathbf K$ which minimizes the error:\n",
    "\n",
    "$$-2(\\mathbf H\\mathbf{\\bar P})^\\mathsf T + 2\\mathbf K(\\mathbf H \\mathbf{\\bar P}\\mathbf H^\\mathsf T + \\mathbf R) = 0 \\\\\n",
    "\\mathbf K(\\mathbf H \\mathbf{\\bar P}\\mathbf H^\\mathsf T + \\mathbf R) = (\\mathbf H\\mathbf{\\bar P})^\\mathsf T \\\\\n",
    "\\mathbf K(\\mathbf H \\mathbf{\\bar P}\\mathbf H^\\mathsf T + \\mathbf R) = \\mathbf{\\bar P}\\mathbf H^\\mathsf T \\\\\n",
    "\\mathbf K= \\mathbf{\\bar P}\\mathbf H^\\mathsf T (\\mathbf H \\mathbf{\\bar P}\\mathbf H^\\mathsf T + \\mathbf R)^{-1}\n",
    "$$\n",
    "\n",
    "This derivation is not quite iron clad as I left out an argument about why minimizing the trace minimizes the total error, but I think it suffices for this book. Any of the standard texts will go into greater detail if you need it.\n",
    "\n",
    "## Numeric Integration of Differential Equations\n",
    "\n",
    "We've been exposed to several numerical techniques to solve linear differential equations. These include state-space methods, the Laplace transform, and van Loan's method. \n",
    "\n",
    "These work well for linear ordinary differential equations (ODEs), but do not work well for nonlinear equations. For example, consider trying to predict the position of a rapidly turning car. Cars maneuver by turning the front wheels. This makes them pivot around their rear axle as it moves forward. Therefore the path will be continuously varying and a linear prediction will necessarily produce an incorrect value. If the change in the system is small enough relative to $\\Delta t$ this can often produce adequate results, but that will rarely be the case with the nonlinear Kalman filters we will be studying in subsequent chapters. \n",
    "\n",
    "For these reasons we need to know how to numerically integrate ODEs. This can be a vast topic that requires several books. However, I will cover a few simple techniques which will work for a majority of the problems you encounter.\n",
    "\n",
    "\n",
    "### Euler's Method\n",
    "\n",
    "Let's say we have the initial condition problem of \n",
    "\n",
    "$$\\begin{gathered}\n",
    "y' = y, \\\\ y(0) = 1\n",
    "\\end{gathered}$$\n",
    "\n",
    "We happen to know the exact answer is $y=e^t$ because we solved it earlier, but for an arbitrary ODE we will not know the exact solution. In general all we know is the derivative of the equation, which is equal to the slope. We also know the initial value: at $t=0$, $y=1$. If we know these two pieces of information we can predict the value at $y(t=1)$ using the slope at $t=0$ and the value of $y(0)$. I've plotted this below.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "t = np.linspace(-1, 1, 10)\n",
    "plt.plot(t, np.exp(t))\n",
    "t = np.linspace(-1, 1, 2)\n",
    "plt.plot(t,t+1, ls='--', c='k');\n",
    "\n",
    "You can see that the slope is very close to the curve at $t=0.1$, but far from it\n",
    "at $t=1$. But let's continue with a step size of 1 for a moment. We can see that at $t=1$ the estimated value of $y$ is 2. Now we can compute the value at $t=2$ by taking the slope of the curve at $t=1$ and adding it to our initial estimate. The slope is computed with $y'=y$, so the slope is 2.\n",
    "\n",
    "import kf_book.book_plots as book_plots\n",
    "\n",
    "t = np.linspace(-1, 2, 20)\n",
    "plt.plot(t, np.exp(t))\n",
    "t = np.linspace(0, 1, 2)\n",
    "plt.plot([1, 2, 4], ls='--', c='k')\n",
    "book_plots.set_labels(x='x', y='y');\n",
    "\n",
    "Here we see the next estimate for y is 4. The errors are getting large quickly, and you might be unimpressed. But 1 is a very large step size. Let's put this algorithm in code, and verify that it works by using a small step size.\n",
    "\n",
    "def euler(t, tmax, y, dx, step=1.):\n",
    "    ys = []\n",
    "    while t < tmax:\n",
    "        y = y + step*dx(t, y)\n",
    "        ys.append(y)\n",
    "        t +=step        \n",
    "    return ys\n",
    "\n",
    "def dx(t, y): return y\n",
    "\n",
    "print(euler(0, 1, 1, dx, step=1.)[-1])\n",
    "print(euler(0, 2, 1, dx, step=1.)[-1])\n",
    "\n",
    "This looks correct. So now let's plot the result of a much smaller step size.\n",
    "\n",
    "ys = euler(0, 4, 1, dx, step=0.00001)\n",
    "plt.subplot(1,2,1)\n",
    "plt.title('Computed')\n",
    "plt.plot(np.linspace(0, 4, len(ys)),ys)\n",
    "plt.subplot(1,2,2)\n",
    "t = np.linspace(0, 4, 20)\n",
    "plt.title('Exact')\n",
    "plt.plot(t, np.exp(t));\n",
    "\n",
    "print('exact answer=', np.exp(4))\n",
    "print('euler answer=', ys[-1])\n",
    "print('difference =', np.exp(4) - ys[-1])\n",
    "print('iterations =', len(ys))\n",
    "\n",
    "Here we see that the error is reasonably small, but it took a very large number of iterations to get three digits of precision. In practice Euler's method is too slow for most problems, and we use more sophisticated methods.\n",
    "\n",
    "Before we go on, let's formally derive Euler's method, as it is the basis for the more advanced Runge Kutta methods used in the next section. In fact, Euler's method is the simplest form of Runge Kutta.\n",
    "\n",
    "\n",
    "Here are the first 3 terms of the Taylor expansion of $y$. An infinite expansion would give an exact answer, so $O(h^4)$ denotes the error due to the finite expansion.\n",
    "\n",
    "$$y(t_0 + h) = y(t_0) + h y'(t_0) + \\frac{1}{2!}h^2 y''(t_0) + \\frac{1}{3!}h^3 y'''(t_0) +  O(h^4)$$\n",
    "\n",
    "Here we can see that Euler's method is using the first two terms of the Taylor expansion. Each subsequent term is smaller than the previous terms, so we are assured that the estimate will not be too far off from the correct value. \n",
    "\n",
    "### Runge Kutta Methods\n",
    "\n",
    "\n",
    "Runge Kutta is the workhorse of numerical integration. There are a vast number of methods in the literature. In practice, using the Runge Kutta algorithm that I present here will solve most any problem you will face. It offers a very good balance of speed, precision, and stability, and it is the 'go to' numerical integration method unless you have a very good reason to choose something different.\n",
    "\n",
    "Let's dive in. We start with some differential equation\n",
    "\n",
    "$$\\ddot{y} = \\frac{d}{dt}\\dot{y}$$.\n",
    "\n",
    "We can substitute the derivative of y with a function f, like so\n",
    "\n",
    "$$\\ddot{y} = \\frac{d}{dt}f(y,t)$$.\n",
    "\n",
    "Deriving these equations is outside the scope of this book, but the Runge Kutta RK4 method is defined with these equations.\n",
    "\n",
    "$$y(t+\\Delta t) = y(t) + \\frac{1}{6}(k_1 + 2k_2 + 2k_3 + k_4) + O(\\Delta t^4)$$\n",
    "\n",
    "$$\\begin{aligned}\n",
    "k_1 &= f(y,t)\\Delta t \\\\\n",
    "k_2 &= f(y+\\frac{1}{2}k_1, t+\\frac{1}{2}\\Delta t)\\Delta t \\\\\n",
    "k_3 &= f(y+\\frac{1}{2}k_2, t+\\frac{1}{2}\\Delta t)\\Delta t \\\\\n",
    "k_4 &= f(y+k_3, t+\\Delta t)\\Delta t\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Here is the corresponding code:\n",
    "\n",
    "def runge_kutta4(y, x, dx, f):\n",
    "    \"\"\"computes 4th order Runge-Kutta for dy/dx.\n",
    "    y is the initial value for y\n",
    "    x is the initial value for x\n",
    "    dx is the difference in x (e.g. the time step)\n",
    "    f is a callable function (y, x) that you supply \n",
    "    to compute dy/dx for the specified values.\n",
    "    \"\"\"\n",
    "    \n",
    "    k1 = dx * f(y, x)\n",
    "    k2 = dx * f(y + 0.5*k1, x + 0.5*dx)\n",
    "    k3 = dx * f(y + 0.5*k2, x + 0.5*dx)\n",
    "    k4 = dx * f(y + k3, x + dx)\n",
    "    \n",
    "    return y + (k1 + 2*k2 + 2*k3 + k4) / 6.\n",
    "\n",
    "Let's use this for a simple example. Let\n",
    "\n",
    "$$\\dot{y} = t\\sqrt{y(t)}$$\n",
    "\n",
    "with the initial values\n",
    "\n",
    "$$\\begin{aligned}t_0 &= 0\\\\y_0 &= y(t_0) = 1\\end{aligned}$$\n",
    "\n",
    "import math\n",
    "import numpy as np\n",
    "t = 0.\n",
    "y = 1.\n",
    "dt = .1\n",
    "\n",
    "ys, ts = [], []\n",
    "\n",
    "def func(y,t):\n",
    "    return t*math.sqrt(y)\n",
    "\n",
    "while t <= 10:\n",
    "    y = runge_kutta4(y, t, dt, func)\n",
    "    t += dt\n",
    "    ys.append(y)\n",
    "    ts.append(t)\n",
    "\n",
    "exact = [(t**2 + 4)**2 / 16. for t in ts]\n",
    "plt.plot(ts, ys)\n",
    "plt.plot(ts, exact)\n",
    "\n",
    "error = np.array(exact) - np.array(ys)\n",
    "print(f\"max error {max(error):.5f}\")\n",
    "\n",
    "## Bayesian Filtering\n",
    "\n",
    "Starting in the Discrete Bayes chapter I used a Bayesian formulation for filtering. Suppose we are tracking an object. We define its *state* at a specific time as its position, velocity, and so on. For example, we might write the state at time $t$ as $\\mathbf x_t = \\begin{bmatrix}x_t &\\dot x_t \\end{bmatrix}^\\mathsf T$. \n",
    "\n",
    "When we take a measurement of the object we are measuring the state or part of it. Sensors are noisy, so the measurement is corrupted with noise. Clearly though, the measurement is determined by the state. That is, a change in state may change the measurement, but a change in measurement will not change the state.\n",
    "\n",
    "In filtering our goal is to compute an optimal estimate for a set of states $\\mathbf x_{0:t}$ from time 0 to time $t$. If we knew $\\mathbf x_{0:t}$ then it would be trivial to compute a set of measurements $\\mathbf z_{0:t}$ corresponding to those states. However, we receive a set of measurements $\\mathbf z_{0:t}$, and want to compute the corresponding states $\\mathbf x_{0:t}$. This is called *statistical inversion* because we are trying to compute the input from the output. \n",
    "\n",
    "Inversion is a difficult problem because there is typically no unique solution. For a given set of states $\\mathbf x_{0:t}$ there is only one possible set of measurements (plus noise), but for a given set of measurements there are many different sets of states that could have led to those measurements. \n",
    "\n",
    "Recall Bayes Theorem:\n",
    "\n",
    "$$P(x \\mid z) = \\frac{P(z \\mid x)P(x)}{P(z)}$$\n",
    "\n",
    "where $P(z \\mid x)$ is the *likelihood* of the measurement $z$, $P(x)$ is the *prior* based on our process model, and $P(z)$ is a normalization constant. $P(x \\mid z)$ is the *posterior*, or the distribution after incorporating the measurement $z$, also called the *evidence*.\n",
    "\n",
    "This is a *statistical inversion* as it goes from $P(z \\mid x)$ to $P(x \\mid z)$. The solution to our filtering problem can be expressed as:\n",
    "\n",
    "$$P(\\mathbf x_{0:t} \\mid \\mathbf z_{0:t}) = \\frac{P(\\mathbf z_{0:t} \\mid \\mathbf x_{0:t})P(\\mathbf x_{0:t})}{P(\\mathbf z_{0:t})}$$\n",
    "\n",
    "That is all well and good until the next measurement $\\mathbf z_{t+1}$ comes in, at which point we need to recompute the entire expression for the range $0:t+1$. \n",
    "\n",
    "In practice this is intractable because we are trying to compute the posterior distribution $P(\\mathbf x_{0:t} \\mid \\mathbf z_{0:t})$ for the state over the full range of time steps. But do we really care about the probability distribution at the third step (say) when we just received the tenth measurement? Not usually. So we relax our requirements and only compute the distributions for the current time step. \n",
    "\n",
    "The first simplification is we describe our process (e.g., the motion model for a moving object) as a *Markov chain*. That is, we say that the current state is solely dependent on the previous state and a transition probability $P(\\mathbf x_k \\mid \\mathbf x_{k-1})$, which is just the probability of going from the last state to the current one. We write:\n",
    "\n",
    "$$\\mathbf x_k \\sim P(\\mathbf x_k \\mid \\mathbf x_{k-1})$$\n",
    "\n",
    "In practice this is extremely reasonable, as many things have the *Markov property*. If you are driving in a parking lot, does your position in the next second depend on whether you pulled off the interstate or were creeping along on a dirt road one minute ago? No. Your position in the next second depends solely on your current position, speed, and control inputs, not on what happened a minute ago. Thus, cars have the Markov property, and we can make this simplification with no loss of precision or generality.\n",
    "\n",
    "The next simplification we make is do define the *measurement model* as depending on the current state $\\mathbf x_k$ with the conditional probability of the measurement given the current state: $P(\\mathbf z_k \\mid \\mathbf x_k)$. We write:\n",
    "\n",
    "$$\\mathbf z_k \\sim P(\\mathbf z_k \\mid \\mathbf x_k)$$\n",
    "\n",
    "We have a recurrence now, so we need an initial condition to terminate it. Therefore we say that the initial distribution is the probablity of the state $\\mathbf x_0$:\n",
    "\n",
    "$$\\mathbf x_0 \\sim P(\\mathbf x_0)$$\n",
    "\n",
    "\n",
    "These terms are plugged into Bayes equation. If we have the state $\\mathbf x_0$ and the first measurement we can estimate $P(\\mathbf x_1 | \\mathbf z_1)$. The motion model creates the prior $P(\\mathbf x_2 \\mid \\mathbf x_1)$. We feed this back into Bayes theorem to compute $P(\\mathbf x_2 | \\mathbf z_2)$. We continue this predictor-corrector algorithm, recursively computing the state and distribution at time $t$ based solely on the state and distribution at time $t-1$ and the measurement at time $t$.\n",
    "\n",
    "The details of the mathematics for this computation varies based on the problem. The **Discrete Bayes** and **Univariate Kalman Filter** chapters gave two different formulations which you should have been able to reason through. The univariate Kalman filter assumes that for a scalar state both the noise and process are linear model are affected by zero-mean, uncorrelated Gaussian noise. \n",
    "\n",
    "The Multivariate Kalman filter makes the same assumption but for states and measurements that are vectors, not scalars. Dr. Kalman was able to prove that if these assumptions hold true then the Kalman filter is *optimal* in a least squares sense. Colloquially this means there is no way to derive more information from the noisy measurements. In the remainder of the book I will present filters that relax the constraints on linearity and Gaussian noise.\n",
    "\n",
    "Before I go on, a few more words about statistical inversion. As Calvetti and Somersalo write in *Introduction to Bayesian Scientific Computing*, \"we adopt the Bayesian point of view: *randomness simply means lack of information*\"[3]. Our state parameterizes physical phenomena that we could in principle measure or compute: velocity, air drag, and so on. We lack enough information to compute or measure their value, so we opt to consider them as random variables. Strictly speaking they are not random, thus this is a subjective position. \n",
    "\n",
    "They devote a full chapter to this topic. I can spare a paragraph. Bayesian filters are possible because we ascribe statistical properties to unknown parameters. In the case of the Kalman filter we have closed-form solutions to find an optimal estimate. Other filters, such as the discrete Bayes filter or the particle filter which we cover in a later chapter, model the probability in a more ad-hoc, non-optimal manner. The power of our technique comes from treating lack of information as a random variable, describing that random variable as a probability distribution, and then using Bayes Theorem to solve the statistical inference problem.\n",
    "\n",
    "## Converting Kalman Filter to a g-h Filter\n",
    "\n",
    "I've stated that the Kalman filter is a form of the g-h filter. It just takes some algebra to prove it. It's more straightforward to do with the one dimensional case, so I will do that. Recall \n",
    "\n",
    "$$\n",
    "\\mu_{x}=\\frac{\\sigma_1^2 \\mu_2 + \\sigma_2^2 \\mu_1} {\\sigma_1^2 + \\sigma_2^2}\n",
    "$$\n",
    "\n",
    "which I will make more friendly for our eyes as:\n",
    "\n",
    "$$\n",
    "\\mu_{x}=\\frac{ya + xb} {a+b}\n",
    "$$\n",
    "\n",
    "We can easily put this into the g-h form with the following algebra\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_{x}&=(x-x) + \\frac{ya + xb} {a+b} \\\\\n",
    "\\mu_{x}&=x-\\frac{a+b}{a+b}x  + \\frac{ya + xb} {a+b} \\\\ \n",
    "\\mu_{x}&=x +\\frac{-x(a+b) + xb+ya}{a+b} \\\\\n",
    "\\mu_{x}&=x+ \\frac{-xa+ya}{a+b}  \\\\\n",
    "\\mu_{x}&=x+ \\frac{a}{a+b}(y-x)\\\\\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "We are almost done, but recall that the variance of estimate is given by \n",
    "\n",
    "$$\\begin{aligned}\n",
    "\\sigma_{x}^2 &= \\frac{1}{\\frac{1}{\\sigma_1^2} +  \\frac{1}{\\sigma_2^2}} \\\\\n",
    "&= \\frac{1}{\\frac{1}{a} +  \\frac{1}{b}}\n",
    "\\end{aligned}$$\n",
    "\n",
    "We can incorporate that term into our equation above by observing that\n",
    "\n",
    "$$ \n",
    "\\begin{aligned}\n",
    "\\frac{a}{a+b} &= \\frac{a/a}{(a+b)/a} = \\frac{1}{(a+b)/a}  \\\\\n",
    " &= \\frac{1}{1 + \\frac{b}{a}} = \\frac{1}{\\frac{b}{b} + \\frac{b}{a}}  \\\\\n",
    " &= \\frac{1}{b}\\frac{1}{\\frac{1}{b} + \\frac{1}{a}} \\\\\n",
    " &= \\frac{\\sigma^2_{x}}{b}\n",
    " \\end{aligned}\n",
    "$$\n",
    "\n",
    "We can tie all of this together with\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mu_{x}&=x+ \\frac{a}{a+b}(y-x) \\\\\n",
    "&= x + \\frac{\\sigma^2_{x}}{b}(y-x) \\\\\n",
    "&= x + g_n(y-x)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$g_n = \\frac{\\sigma^2_{x}}{\\sigma^2_{y}}$$\n",
    "\n",
    "The end result is multiplying the residual of the two measurements by a constant and adding to our previous value, which is the $g$ equation for the g-h filter. $g$ is the variance of the new estimate divided by the variance of the measurement. Of course in this case $g$ is not a constant as it varies with each time step as the variance changes. We can also derive the formula for $h$ in the same way. It is not a particularly illuminating derivation and I will skip it. The end result is\n",
    "\n",
    "$$h_n = \\frac{COV (x,\\dot x)}{\\sigma^2_{y}}$$\n",
    "\n",
    "The takeaway point is that $g$ and $h$ are specified fully by the variance and covariances of the measurement and predictions at time $n$. In other words, we are picking a point between the measurement and prediction by a scale factor determined by the quality of each of those two inputs.\n",
    "\n",
    "## References\n",
    "\n",
    " * [1] C.B. Molwer and C.F. Van Loan \"Nineteen Dubious Ways to Compute the Exponential of a Matrix, Twenty-Five Years Later,\", *SIAM Review 45, 3-49*. 2003.\n",
    "\n",
    "\n",
    " * [2] C.F. van Loan, \"Computing Integrals Involving the Matrix Exponential,\" IEEE *Transactions Automatic Control*, June 1978.\n",
    " \n",
    " \n",
    " * [3] Calvetti, D and Somersalo E, \"Introduction to Bayesian Scientific Computing: Ten Lectures on Subjective Computing,\", *Springer*, 2007.\n",
    " \n",
    " * [4] Brown, R. G. and Hwang, P. Y.C., \"Introduction to Random Signals and Applied Kalman Filtering\", *Wiley and Sons*, Fourth Edition, p.143-147, 2012. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
